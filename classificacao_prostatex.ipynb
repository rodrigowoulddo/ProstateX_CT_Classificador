{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de imagens de tomografia computadorizada de próstata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Downloading https://files.pythonhosted.org/packages/56/e1/7185572caa15620decf8d7f9492f7406ac221f878cc82e922fc36a0e5aac/pydicom-1.1.0-1-py2.py3-none-any.whl (6.7MB)\n",
      "Installing collected packages: pydicom\n",
      "Successfully installed pydicom-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypng\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/b1/c8dfcf50feb12a30be7d95c5f45d638704682487d8e50419ef41463febcd/pypng-0.0.18.tar.gz (377kB)\n",
      "Building wheels for collected packages: pypng\n",
      "  Running setup.py bdist_wheel for pypng: started\n",
      "  Running setup.py bdist_wheel for pypng: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\gabrielle\\AppData\\Local\\pip\\Cache\\wheels\\ed\\30\\6c\\21dd4d267f47ea09fb57881b30fe16f7231b71bd26dea38afc\n",
      "Successfully built pypng\n",
      "Installing collected packages: pypng\n",
      "Successfully installed pypng-0.0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pypng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras)\n",
      "Collecting keras-applications==1.0.4 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras)\n",
      "Collecting keras-preprocessing==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/2a/c3fe6035f0a8726e5b210680af3ccaf826f4a64ce7306e57017aba749447/tensorflow-1.10.0-cp36-cp36m-win_amd64.whl (37.7MB)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Collecting tensorboard<1.11.0,>=1.10.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
      "Collecting numpy<=1.14.5,>=1.13.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/b7/0c804e0bcba6505f8392d042d5e333a5e06f308e019517111fbc7767a0bc/numpy-1.14.5-cp36-none-win_amd64.whl (13.4MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/da/03e722b7981ab3222f292f735a3c157b1d1bca120c479d7e273273828170/grpcio-1.14.2-cp36-cp36m-win_amd64.whl (1.5MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools<=39.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Collecting protobuf>=3.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/df/d606d07cff0fc8d22abcc54006c0247002d11a7f2d218eb008d48e76851d/protobuf-3.6.1-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/86/67f55488ec68982270142c340cd23cd2408835dc4b24bd1d1f1e114f24c3/absl-py-0.4.1.tar.gz (88kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n",
      "Building wheels for collected packages: gast, termcolor, absl-py\n",
      "  Running setup.py bdist_wheel for gast: started\n",
      "  Running setup.py bdist_wheel for gast: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\gabrielle\\AppData\\Local\\pip\\Cache\\wheels\\9a\\1f\\0e\\3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for termcolor: started\n",
      "  Running setup.py bdist_wheel for termcolor: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\gabrielle\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py: started\n",
      "  Running setup.py bdist_wheel for absl-py: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\gabrielle\\AppData\\Local\\pip\\Cache\\wheels\\78\\a3\\a3\\689120b95c26b9a21be6584b4b482b0fda0a1b60efd30af558\n",
      "Successfully built gast termcolor absl-py\n",
      "Installing collected packages: gast, markdown, numpy, protobuf, tensorboard, grpcio, termcolor, astor, absl-py, tensorflow\n",
      "  Found existing installation: numpy 1.13.1\n",
      "    Uninstalling numpy-1.13.1:\n",
      "      Successfully uninstalled numpy-1.13.1\n",
      "Successfully installed absl-py-0.4.1 astor-0.7.1 gast-0.2.0 grpcio-1.14.2 markdown-2.6.11 numpy-1.14.5 protobuf-3.6.1 tensorboard-1.10.0 tensorflow-1.10.0 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de paths e arquivos treino / teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = 'imagens/treinamento'\n",
    "validation_data = 'imagens/validacao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000-12-000007.png\n",
      "0002-12-000007.png\n",
      "0005-12-000007.png\n",
      "0014-12-000007.png\n",
      "0015-12-000007.png\n",
      "0018-12-000007.png\n",
      "0019-12-000007.png\n",
      "0026-12-000007.png\n",
      "0028-12-000007.png\n",
      "0031-12-000007.png\n",
      "0035-12-000007.png\n",
      "0037-12-000007.png\n",
      "0040-12-000007.png\n",
      "0041-12-000007.png\n",
      "0046-12-000007.png\n",
      "0054-12-000007.png\n",
      "0055-12-000007.png\n",
      "0067-12-000007.png\n",
      "0071-12-000007.png\n",
      "0077-12-000007.png\n",
      "0078-12-000007.png\n",
      "0082-12-000007.png\n",
      "0092-12-000007.png\n",
      "0094-12-000007.png\n",
      "0095-12-000007.png\n",
      "0097-12-000007.png\n",
      "0099-12-000007.png\n",
      "0102-12-000007.png\n",
      "0103-12-000007.png\n",
      "0104-12-000007.png\n",
      "0105-12-000007.png\n",
      "0106-12-000007.png\n",
      "0111-12-000007.png\n",
      "0114-12-000007.png\n",
      "0115-12-000007.png\n",
      "0117-12-000007.png\n",
      "0118-12-000007.png\n",
      "0119-12-000007.png\n",
      "0121-12-000007.png\n",
      "0123-12-000007.png\n",
      "0125-12-000007.png\n",
      "0126-12-000007.png\n",
      "0127-12-000007.png\n",
      "0128-12-000007.png\n",
      "0129-12-000007.png\n",
      "0131-12-000007.png\n",
      "0139-12-000007.png\n",
      "0143-12-000007.png\n",
      "0164-12-000007.png\n",
      "0169-12-000007.png\n",
      "0179-12-000007.png\n",
      "0181-12-000007.png\n",
      "0183-12-000007.png\n",
      "0184-12-000007.png\n",
      "0186-12-000007.png\n",
      "0001-12-000007.png\n",
      "0002-12-000007.png\n",
      "0003-12-000007.png\n",
      "0004-12-000007.png\n",
      "0005-12-000007.png\n",
      "0006-12-000007.png\n",
      "0007-12-000007.png\n",
      "0008-12-000007.png\n",
      "0009-12-000007.png\n",
      "0010-12-000007.png\n",
      "0011-12-000007.png\n",
      "0012-12-000007.png\n",
      "0013-12-000007.png\n",
      "0016-12-000007.png\n",
      "0017-12-000007.png\n",
      "0020-12-000007.png\n",
      "0021-12-000007.png\n",
      "0022-12-000007.png\n",
      "0023-12-000007.png\n",
      "0024-12-000007.png\n",
      "0025-12-000007.png\n",
      "0027-12-000007.png\n",
      "0028-12-000007.png\n",
      "0029-12-000007.png\n",
      "0030-12-000007.png\n",
      "0031-12-000007.png\n",
      "0032-12-000007.png\n",
      "0033-12-000007.png\n",
      "0034-12-000007.png\n",
      "0035-12-000007.png\n",
      "0036-12-000007.png\n",
      "0037-12-000007.png\n",
      "0038-12-000007.png\n",
      "0039-12-000007.png\n",
      "0040-12-000007.png\n",
      "0042-12-000007.png\n",
      "0043-12-000007.png\n",
      "0044-12-000007.png\n",
      "0045-12-000007.png\n",
      "0046-12-000007.png\n",
      "0047-12-000007.png\n",
      "0048-12-000007.png\n",
      "0049-12-000007.png\n",
      "0050-12-000007.png\n",
      "0051-12-000007.png\n",
      "0052-12-000007.png\n",
      "0053-12-000007.png\n",
      "0054-12-000007.png\n",
      "0056-12-000007.png\n",
      "0057-12-000007.png\n",
      "0058-12-000007.png\n",
      "0059-12-000007.png\n",
      "0060-12-000007.png\n",
      "0061-12-000007.png\n",
      "0062-12-000007.png\n",
      "0063-12-000007.png\n",
      "0064-12-000007.png\n",
      "0065-12-000007.png\n",
      "0066-12-000007.png\n",
      "0067-12-000007.png\n",
      "0068-12-000007.png\n",
      "0069-12-000007.png\n",
      "0070-12-000007.png\n",
      "0072-12-000007.png\n",
      "0073-12-000007.png\n",
      "0074-12-000007.png\n",
      "0075-12-000007.png\n",
      "0076-12-000007.png\n",
      "0079-12-000007.png\n",
      "0080-12-000007.png\n",
      "0081-12-000007.png\n",
      "0083-12-000007.png\n",
      "0084-12-000007.png\n",
      "0085-12-000007.png\n",
      "0086-12-000007.png\n",
      "0087-12-000007.png\n",
      "0088-12-000007.png\n",
      "0089-12-000007.png\n",
      "0090-12-000007.png\n",
      "0091-12-000007.png\n",
      "0093-12-000007.png\n",
      "0095-12-000007.png\n",
      "0096-12-000007.png\n",
      "0098-12-000007.png\n",
      "0099-12-000007.png\n",
      "0100-12-000007.png\n",
      "0101-12-000007.png\n",
      "0103-12-000007.png\n",
      "0104-12-000007.png\n",
      "0105-12-000007.png\n",
      "0106-12-000007.png\n",
      "0107-12-000007.png\n",
      "0108-12-000007.png\n",
      "0109-12-000007.png\n",
      "0110-12-000007.png\n",
      "0112-12-000007.png\n",
      "0113-12-000007.png\n",
      "0114-12-000007.png\n",
      "0116-12-000007.png\n",
      "0117-12-000007.png\n",
      "0118-12-000007.png\n",
      "0120-12-000007.png\n",
      "0121-12-000007.png\n",
      "0122-12-000007.png\n",
      "0124-12-000007.png\n",
      "0126-12-000007.png\n",
      "0128-12-000007.png\n",
      "0130-12-000007.png\n",
      "0131-12-000007.png\n",
      "0132-12-000007.png\n",
      "0133-12-000007.png\n",
      "0134-12-000007.png\n",
      "0135-12-000007.png\n",
      "0136-12-000007.png\n",
      "0137-12-000007.png\n",
      "0138-12-000007.png\n",
      "0139-12-000007.png\n",
      "0140-12-000007.png\n",
      "0141-12-000007.png\n",
      "0142-12-000007.png\n",
      "0144-12-000007.png\n",
      "0145-12-000007.png\n",
      "0146-12-000007.png\n",
      "0149-12-000007.png\n",
      "0150-12-000007.png\n",
      "0151-12-000007.png\n",
      "0152-12-000007.png\n",
      "0154-12-000007.png\n",
      "0155-12-000007.png\n",
      "0156-12-000007.png\n",
      "0157-12-000007.png\n",
      "0158-12-000007.png\n",
      "0159-12-000007.png\n",
      "0160-12-000007.png\n",
      "0161-12-000007.png\n",
      "0162-12-000007.png\n",
      "0163-12-000007.png\n",
      "0165-12-000007.png\n",
      "0166-12-000007.png\n",
      "0167-12-000007.png\n",
      "0168-12-000007.png\n",
      "0170-12-000007.png\n",
      "0171-12-000007.png\n",
      "0172-12-000007.png\n",
      "0173-12-000007.png\n",
      "0174-12-000007.png\n",
      "0175-12-000007.png\n",
      "0176-12-000007.png\n",
      "0177-12-000007.png\n",
      "0178-12-000007.png\n",
      "0180-12-000007.png\n",
      "0182-12-000007.png\n",
      "0184-12-000007.png\n",
      "0185-12-000007.png\n"
     ]
    }
   ],
   "source": [
    "import pylab\n",
    "import pydicom as dicom\n",
    "import glob\n",
    "import png\n",
    "import os\n",
    "\n",
    "#Transforma as imagens DICOM em PNG\n",
    "\n",
    "diretorio_list = ['imagens/treinamento/true/', 'imagens/validacao/true/',\n",
    "                  'imagens/treinamento/false/', 'imagens/validacao/false/']\n",
    "for diretorio in diretorio_list:\n",
    "    for img in glob.glob(diretorio + '*.dcm'):\n",
    "          mri_file = open(img, 'rb')\n",
    "          imagem = dicom.read_file(mri_file)\n",
    "          mri_file.close()\n",
    "\n",
    "          shape = imagem.pixel_array.shape\n",
    "\n",
    "          image_2d = []\n",
    "          max_val = 0\n",
    "          for row in imagem.pixel_array:\n",
    "              pixels = []\n",
    "              for col in row:\n",
    "                  pixels.append(col)\n",
    "                  if col > max_val: max_val = col\n",
    "              image_2d.append(pixels)\n",
    "\n",
    "          image_2d_scaled = []\n",
    "          for row in image_2d:\n",
    "              row_scaled = []\n",
    "              for col in row:\n",
    "                  col_scaled = int((float(col) / float(max_val)) * 255.0)\n",
    "                  row_scaled.append(col_scaled)\n",
    "              image_2d_scaled.append(row_scaled)\n",
    "\n",
    "          png_nome = os.path.basename(img)[:-3] + 'png'\n",
    "          print(png_nome)\n",
    "          png_file = open(diretorio+png_nome, 'wb')\n",
    "          w = png.Writer(shape[1], shape[0], greyscale=True)\n",
    "          w.write(png_file, image_2d_scaled)\n",
    "          png_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182 images belonging to 2 classes.\n",
      "Found 27 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        training_data,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(256, 256,...)`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=10, epochs=10, validation_steps=24)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 17s 2s/step - loss: 3.8976 - acc: 0.7125 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 13s 1s/step - loss: 4.2336 - acc: 0.7373 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 15s 2s/step - loss: 4.6340 - acc: 0.7125 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 3.5472 - acc: 0.7799 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 5.1199 - acc: 0.6823 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 4.0051 - acc: 0.7515 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 4.1303 - acc: 0.7438 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 4.4883 - acc: 0.7215 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 4.1052 - acc: 0.7453 - val_loss: 4.1788 - val_acc: 0.7407\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 4.3592 - acc: 0.7295 - val_loss: 4.1788 - val_acc: 0.7407\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (Unable to open file: name = 'modelos/checkpoint.h5', errno = 2, error message = 'no such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-bc20ffd27fc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         nb_val_samples=nb_validation_samples)\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'modelos/checkpoint.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite)\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m             \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (Unable to open file: name = 'modelos/checkpoint.h5', errno = 2, error message = 'no such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "#Definição de variáveis de treinamento\n",
    "\n",
    "nb_epoch  = 10\n",
    "nb_train_samples = 160\n",
    "nb_validation_samples = 24\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "model.save_weights('modelos/checkpoint.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0164\n",
      "Resultado:  [[9.670172e-24]]\n",
      "0169\n",
      "Resultado:  [[6.0065226e-24]]\n",
      "0179\n",
      "Resultado:  [[1.0256557e-25]]\n",
      "0181\n",
      "Resultado:  [[6.2094616e-27]]\n",
      "0183\n",
      "Resultado:  [[3.1304208e-21]]\n",
      "0184\n",
      "Resultado:  [[9.823733e-23]]\n",
      "0186\n",
      "Resultado:  [[6.073041e-23]]\n",
      "0161\n",
      "Resultado:  [[8.471261e-25]]\n",
      "0162\n",
      "Resultado:  [[3.1370026e-24]]\n",
      "0163\n",
      "Resultado:  [[4.5950444e-23]]\n",
      "0165\n",
      "Resultado:  [[6.7217235e-25]]\n",
      "0166\n",
      "Resultado:  [[9.9987127e-29]]\n",
      "0167\n",
      "Resultado:  [[1.3158549e-15]]\n",
      "0168\n",
      "Resultado:  [[1.9386811e-27]]\n",
      "0170\n",
      "Resultado:  [[1.800421e-22]]\n",
      "0171\n",
      "Resultado:  [[1.7998077e-17]]\n",
      "0172\n",
      "Resultado:  [[2.5785978e-24]]\n",
      "0173\n",
      "Resultado:  [[3.1746113e-31]]\n",
      "0174\n",
      "Resultado:  [[1.9842317e-27]]\n",
      "0175\n",
      "Resultado:  [[1.3785829e-23]]\n",
      "0176\n",
      "Resultado:  [[8.101425e-17]]\n",
      "0177\n",
      "Resultado:  [[5.137979e-26]]\n",
      "0178\n",
      "Resultado:  [[2.0519278e-24]]\n",
      "0180\n",
      "Resultado:  [[1.0083562e-27]]\n",
      "0182\n",
      "Resultado:  [[4.2859526e-27]]\n",
      "0184\n",
      "Resultado:  [[9.823733e-23]]\n",
      "0185\n",
      "Resultado:  [[5.6429926e-24]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "diretorio_list = ['imagens/validacao/true/', 'imagens/validacao/false/']\n",
    "for diretorio in diretorio_list:\n",
    "    for img in glob.glob(diretorio + '*.png'):\n",
    "        print(Image.open(img).filename[-18:-14])\n",
    "\n",
    "        img = image.load_img(img, target_size=(256, 256))\n",
    "        img_teste = image.img_to_array(img)\n",
    "        img_teste = np.expand_dims(img_teste, axis=0) * 1./255\n",
    "        prediction = model.predict(img_teste)\n",
    "        \n",
    "        print(\"Resultado: \", prediction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
